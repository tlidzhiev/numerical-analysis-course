\ProvidesFile{lecture-08.tex}[Лекция 8]

\newpage

\section{Собственные векторы и собственные значения}

\begin{definition}
    \textit{Собственным вектором} $v$ матрицы $A_{n \times n}$ с соответствующим \textit{собственным значением} $\lambda$ называется вектор, для которого выполнено:

    \[
    A v = \lambda v
    \]
\end{definition}

\subsection*{Постановка задачи: SPD матрица}

Задача нахождения (всех или нескольких) собственных векторов и собственных значений часто возникает на практике, особенно случай, когда $A_n$ является SPD матрицей, который будет рассматриваться сейчас

Для SPD матрицы известно, что существует ортонормированный базис из собственных векторов $e_1, \ldots, e_n$ с собственными значениями $\lambda_1, \ldots, \lambda_n$, где $\lambda_i > 0$

\subsection{Степенной метод}

\subsubsection*{Описание метода}

Следующий метод позволяет найти собственный вектор и соответствующее наибольшее собственное значение матрицы $A$

\begin{itemize}
    \item Сгенерируем случайный вектор $v_0: v^{\top} v = 1$

    \item Посчитаем $x_1 = A v_0$ и отнормируем его

    \item Проделаем то же самое с вектором $v_0 = x_1$

    \item При достаточном количество итераций получим $v_0$ --- собственный вектор с наибольшим собственным значением:

    \[
    \lambda = \frac{v_1^{\top} v_0}{v_0^{\top} v_0}
    \]
\end{itemize}

\subsubsection*{Сходимость метода}

Введем $\lVert \cdot \rVert_{2}$ норму. Пусть у матрицы $A$ есть базис из ортонормированных собственных векторов $e_1, \ldots, e_n$ и соответствующими собственными значениями $\lambda_1 > \lambda_2 \geqslant \ldots \geqslant \lambda_n$. Пусть $v_{0} = \sum x_i e_i$ --- некоторый вектор единичной длины с $x_1 \neq 1$. Определим последовательность

\[
v_{k+1} = \frac{A v_{k}}{\lVert A v_{k} \rVert}
\]



\[
\lVert A v_{k} \rVert \cdot v_{k+1} = A v_{k} = A^k v_0 =
%
\sum\limits_{i = 1}^n x_i A^k e_i =
%
\sum\limits_{i = 1}^n x_i \lambda_i^k e_i =
%
\lambda_1^k \left(
                x_1 e_1 + \sum\limits_{i = 2}^n x_i \cdot \left(\frac{\lambda_i}{\lambda_1}\right)^k e_i
            \right)
\]

Вспомним, что $\lambda_i / \lambda_1 < 1$, поэтому при достаточно больших $k$:

\[
\lVert A v_{k} \rVert \cdot v_{k+1} = A v_{k} =  \lambda_1^k (x_1 e_1 + \varepsilon_{k}),
\]

где $\lVert \varepsilon_{k} \rVert \longrightarrow 0$. Рассмотрим при $k \longrightarrow \infty$

\[
\lVert v_{k+1} - e_1 \rVert=
%
\left\lVert \frac{A v_{k}}{\lVert A v_{k} \rVert} - e_1 \right\rVert =
%
\frac{1}{ \lVert A v_{k} \rVert } \cdot \left\lVert \lambda_1^k (x_1 e_1 + \varepsilon_{k}) - \lVert A v_{k} \rVert \cdot e_1 \right\rVert \leqslant
%
\frac{1}{ \lVert A v_{k} \rVert } \cdot \Big| \lambda_1^k x_1 -  \lVert A v_{k} \rVert \Big| \cdot \lVert e_1 \rVert \longrightarrow 0
\]

Теперь последовательность:

\[
r_{k+1} =
\frac{
    \langle v_{k+1}, v_{k} \rangle
}{
    \langle v_{k}, v_{k} \rangle
} =
%
\frac{
    v_{k}^{\top} A v_k
}{
    v_k^{\top} v_k
} \longrightarrow
%
\lambda \cdot \frac{
    v_{k}^{\top} v_k
}{
    v_k^{\top} v_k
} = \lambda
\]

\subsubsection*{Как искать остальные?}

Зафиксируем сколь угодно малое $\varepsilon > 0$. Пусть мы нашли собственный вектор $v_1$ с наибольшим собственным значением $\lambda_1$. Построим матрицу $B = A - (\lambda_1 - \varepsilon) v_1 v_1^{\top}$. Так как $A$ является SPD матрицей, то

\[
A = U D U^{\top},
\]

где $U$ --- ортогональная матрица, столбцы которой являются ортонормированными собственными векторами, $D$ --- диагональная матрица из собственных значений $\lambda_i > \varepsilon$. Поэтому $A = \sum \lambda_i v_i v_i^{\top}$. Тогда

\[
B = A - (\lambda_1 - \varepsilon) v_1 v_1^{\top} = \varepsilon v_1 v_1^{\top} + \sum\limits_{i = 2}^n \lambda_i v_i v_i^{\top}
\]

Тогда если применить степенной метод для матрицы $B$, то мы можем получить собственный вектор со следующим по величине собственным значением

\paragraph{Замечание} Чтобы найти наименьшее собственное значение и соответствующий собственный вектор, то можем применить алгоритм к матрице $A^{-1}$. Чтобы вычислить $A^{-1} v_k$, мы можем вместо поиска $A^{-1}$, решать СЛУ $Az_k = v_k \iff z_k = A^{-1} v_k$

\subsubsection*{Поиск конкретного собственного значения}

Пусть у матрицы $A$ есть собственные значения $\lambda_1, \ldots, \lambda_n$ и мы хотим найти $\lambda_i$. Пусть мы знаем некоторое приближение $\lambda_i^{\star}$. Определим тогда матрицу $B = A - \lambda_i^{\star} I$ и рассмотрим ее спектр

\[
\spec(B) = \left\{ \lambda_k - \lambda_i^{\star} \right\} \implies \spec(B^{-1}) = \left\{ \frac{1}{\lambda_k - \lambda_i^{\star}} \right\}
\]

Получается, что если мы подобрали хорошее начальное приближение $\lambda_i^{\star}$, то $1 / (\lambda_i - \lambda_i^{\star})$ --- будем наибольшим собственным значением матрицы $B^{-1}$, которое мы можем найти с помощью степенного метода

\subsection{QR-разложение}

Следующий метод позволяет найти сразу несколько $m$ наибольших собственных значений и собственных векторов

Введем $\lVert \cdot \rVert_{2}$ норму. В этом методе нам понадобится процесс \href{https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process}{ортогонализации Грамма-Шмидта}. Пусть у нас есть векторы $v_1, \ldots, v_n$ и мы хотим получить ортонормированный базис $e_1, \ldots e_n$. Процесс описывается следующим образом:

\begin{itemize}
    \item Пусть $u_1 = v_1$. Теперь будем вычислять векторы $u_2, \ldots, u_n$ следующим образом:

    \[
    u_k = v_k - \sum\limits_{j = 1}^{k-1} \pr_{u_j} (v_k),
    \]

    где $\pr_{u_j} (v_k)$ --- проекция вектора $v_k$ на $u_j$

    \item Теперь $e_i = u_i / \lVert u_i \rVert$
\end{itemize}

\subsubsection*{Описание метода}

Пусть $V_{n \times m} = V_0 = (v_1 | \ldots v_m)$ --- матрица, чьи столбцы $v_i$ являются ортонормированными векторами. Тогда будем итеративно вычислять матрицу:

\[
V_{k+1} = \mathrm{ORT}(A V_k),
\]

где $\mathrm{ORT}$ --- процесс ортогонализации Грамма-Шмидта

При достаточно большом $k$ мы получим, что столбцы матрицы $V_k$ являются собственными векторами $e_1, \ldots, e_m$ с собственными значениями $\lambda_1 \geqslant \ldots \geqslant \lambda_m$

\subsubsection*{Сходимость метода}

Сходимость этого метода доказывается аналогично прошлому методу

\paragraph{Замечание} Аналогично прошлому методу мы можем найти первые $m$ наименьших собственных значений, применив метод к матрице $A^{-1}$
